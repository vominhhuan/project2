{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teYJxL_cNsRo"
      },
      "source": [
        "<h2 style=\"color:blue\" align=\"center\">Quantization Tutorial</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "311fNSGDNsRr"
      },
      "source": [
        "Quantization is a technique to downsize a trained model so that you can deploy it on EDGE devices. In this tutorial we will,\n",
        "\n",
        "(1) Train a hand written digits model\n",
        "\n",
        "(2) Export to a disk and check the size of that model\n",
        "\n",
        "(3) Use two techniques for quantization (1) post training quantization (3) quantization aware training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HMyJz4AiNsRu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F1LhShbNNsRv",
        "outputId": "22a78831-a492-45b3-d28e-26577a10a0af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4947TmmmNsRv",
        "outputId": "67f5c59f-8d84-462c-b035-5640923d6407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxVDuHV8NsRw",
        "outputId": "02a8b07c-1246-48ae-a497-b6eb7515a99a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb3HCurjNsRw",
        "outputId": "8960f8c6-9828-4574-85ec-97bb5a6d6ad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEX12CptNsRx",
        "outputId": "2f220b78-05ec-4292-cf97-da3590c953ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x255fe7bb760>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.matshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMkV9U04NsRx",
        "outputId": "8e57919f-2edf-4624-ef91-658ce768ed64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvFJlJ89NsRx"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asOhVnRbNsRy"
      },
      "outputs": [],
      "source": [
        "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
        "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9xFgDDgNsRy",
        "outputId": "2e9dc132-801b-49ba-8c98-02a089c042ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_flattened.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uym9Y6xhNsRy"
      },
      "source": [
        "<h3 style='color:purple'>Using Flatten layer so that we don't have to call .reshape on input dataset</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bSepjKctNsRy",
        "outputId": "1bb446a0-5170-4c48-d5cc-b055f41bd7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2734 - accuracy: 0.9226\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1245 - accuracy: 0.9635\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0866 - accuracy: 0.9745\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0652 - accuracy: 0.9800\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0516 - accuracy: 0.9847\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x25bbb173820>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vjXb2Q4NsRz",
        "outputId": "828133fb-2bdf-42c7-86fc-27b16c776a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9708\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.08878576755523682, 0.97079998254776]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLl7GxNPNsRz",
        "outputId": "e4aeaaea-f107-457f-aa68-4fb31e39488b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"./saved_model/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1PezW1gNsRz"
      },
      "source": [
        "<h3 style='color:blue'>(1) Post training quantization</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4FMD6FrNsRz"
      },
      "source": [
        "**Without quantization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4JgQ_fbNsR0"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg91h2DUNsR0"
      },
      "source": [
        "**With quantization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpWLopaRNsR0"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"./saved_model\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJIcw8-jNsR0"
      },
      "source": [
        "Read this article for post training quantization: https://www.tensorflow.org/model_optimization/guide/quantization/post_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mQtif2MNsR0",
        "outputId": "a53bc11e-8f8d-4dd1-fe98-8003b2797e68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "319792"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hXGt7GuyNsR0",
        "outputId": "6a53efca-a3f4-46e6-e210-c022da7beb60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84752"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMBzUytXNsR1"
      },
      "source": [
        "You can see above that quantizated model is 1/4th the size of a non quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrNik3V4NsR1"
      },
      "outputs": [],
      "source": [
        "with open(\"tflite_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC5H7K3FNsR1"
      },
      "outputs": [],
      "source": [
        "with open(\"tflite_quant_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION"
      ],
      "metadata": {
        "id": "n_VOIvtrQyRd",
        "outputId": "d2bf323c-df24-4d30-ed91-7406679955af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbQpD6AMNsR1"
      },
      "source": [
        "Once you have above files saved to a disk, check their sizes. Quantized model will be obvi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "y2ombKO8RsIy",
        "outputId": "965f9e17-87b0-4ccc-8b9a-0221aaf826d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 225 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 235 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 238 kB 15.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "metadata": {
        "id": "aTdS8bh5R4yT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnaUn3AeNsR1"
      },
      "source": [
        "<h3 style='color:blue'>(2) Quantization aware training</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1EyzdeOYNsR1",
        "outputId": "111fc052-a59c-4b31-f0d9-c73114823a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0dea9a06e16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# q_aware stands for for quantization aware.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mq_aware_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# `quantize_model` requires a recompile.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m q_aware_model.compile(optimizer='adam',\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM6uJwtzNsR2",
        "outputId": "fb533f9e-1069-432c-872a-0ae6cab54249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0438 - accuracy: 0.9866\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x255fe86ba30>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q_aware_model.fit(X_train, y_train, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFDxQV3INsR2",
        "outputId": "2adb4419-3c9b-4c64-d73a-2e7fd4d4942f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.9755\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.08016839623451233, 0.9754999876022339]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q_aware_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TMs00FzVNsR2",
        "outputId": "b18a195e-cd4a-4d34-f79b-aa0bdbd696dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as flatten_layer_call_fn, flatten_layer_call_and_return_conditional_losses, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\dhava\\AppData\\Local\\Temp\\tmpqnsx4bvx\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\dhava\\AppData\\Local\\Temp\\tmpqnsx4bvx\\assets\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_qaware_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_5nnFGRNsR2",
        "outputId": "2fc69f20-3e35-4467-ca83-1ef341318222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "82376"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tflite_qaware_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HHzs4NmNsR2"
      },
      "outputs": [],
      "source": [
        "with open(\"tflite_qaware_model.tflite\", 'wb') as f:\n",
        "    f.write(tflite_qaware_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}